# Core
fastapi>=0.109.0
a2wsgi>=1.9.0
python-dotenv>=1.0.0
pydantic>=2.5.3
uvicorn>=0.27.0
requests>=2.31.0

# AI & RAG
langchain>=0.1.0
langchain-groq>=0.0.1
langchain-community>=0.0.13
groq>=0.4.1

# Database
supabase>=2.3.0

# ML - lightweight API client only (no transformers/torch)
huggingface-hub>=0.20.0

# NOTE: Heavy dependencies removed for production deployment:
# - langchain-huggingface (includes torch/transformers - 1GB+)
# - pypdf (only needed for local ingestion scripts)
# - semantic-router (pulls in litellm ~500MB + numpy dependencies)
# Using lightweight custom implementations instead
