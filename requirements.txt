# Core
fastapi>=0.109.0
a2wsgi>=1.9.0
python-dotenv>=1.0.0
pydantic>=2.5.3
uvicorn>=0.27.0
requests>=2.31.0

# AI & RAG
groq>=0.4.1


# LLM Infrastructure
litellm>=1.0.0  # Unified LLM interface with automatic provider fallback

# Reranking
cohere>=5.0.0  # Cohere Rerank API (free tier available)

# Hybrid Search
# rank-bm25 removed (unused)

# Database
supabase>=2.3.0

# ML - API client
huggingface-hub>=0.20.0

# NOTE: Moved from heavy local models to API-based approach for serverless
# - Using LiteLLM for provider fallback (Groq → OpenAI → Claude)
# - Using Cohere API for reranking (free tier)
# - Using HuggingFace Inference API for embeddings
